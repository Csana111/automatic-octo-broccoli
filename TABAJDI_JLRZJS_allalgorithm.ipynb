{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZwvVYjowk92Q",
    "ExecuteTime": {
     "end_time": "2024-01-09T20:27:17.473603700Z",
     "start_time": "2024-01-09T20:27:17.469819700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Error metrics\n",
    "error_metrics = {\n",
    "    'MSE': mean_squared_error,\n",
    "    'rMSE': lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    'relative': lambda y_true, y_pred: np.mean(np.abs((y_true - y_pred) / y_true)) * 100,\n",
    "    'relativeSE': lambda y_true, y_pred: np.mean(np.square((y_true - y_pred) / y_true)) * 100,\n",
    "    'absoluteSE': mean_absolute_error,\n",
    "    'statistical correlation': r2_score\n",
    "}"
   ],
   "metadata": {
    "id": "taEvPHS-lef1",
    "ExecuteTime": {
     "end_time": "2024-01-09T20:27:17.497474300Z",
     "start_time": "2024-01-09T20:27:17.475789800Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def perform_grid_search(model, param_grid, X_train, y_train, X_test, y_test, model_name):\n",
    "    grd = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error',\n",
    "                       verbose=2, n_jobs=-1)\n",
    "    grd.fit(X_train, y_train)\n",
    "    best = grd.best_params_\n",
    "    print(f\"Best Parameters for {model_name}:\", best)\n",
    "\n",
    "    model_ = model.set_params(**best)\n",
    "    model_.fit(X_train, y_train)\n",
    "    y_pred = model_.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error for {model_name} (Best Model):\", mse)\n",
    "\n",
    "    return model_, mse, y_pred"
   ],
   "metadata": {
    "id": "O0VD5Tfeljs7",
    "ExecuteTime": {
     "end_time": "2024-01-09T20:27:17.498581500Z",
     "start_time": "2024-01-09T20:27:17.484471700Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def model_selection(models, X_train, y_train, X_test, y_test, error_metrics):\n",
    "    model_errors = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        errors = {}\n",
    "        for error_name, error_func in error_metrics.items():\n",
    "            errors[error_name] = error_func(y_test, y_pred)\n",
    "\n",
    "        model_errors[model_name] = errors\n",
    "\n",
    "    return model_errors"
   ],
   "metadata": {
    "id": "_ystLmBflljP",
    "ExecuteTime": {
     "end_time": "2024-01-09T20:27:17.508967500Z",
     "start_time": "2024-01-09T20:27:17.492790300Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def run_models(X_train, X_test, y_train, y_test, validation, validation_ids, dir_path):\n",
    "    # K-Nearest Neighbors\n",
    "    knn_model = KNeighborsRegressor()\n",
    "    knn_param_grid = {'n_neighbors': [5, 17, 18, 19], 'weights': ['uniform', 'distance'],\n",
    "                      'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [5, 10, 15],\n",
    "                      'p': [1, 2]}\n",
    "    knn_best_model, knn_mse, knn_y_pred = perform_grid_search(knn_model, knn_param_grid, X_train, y_train, X_test,\n",
    "                                                              y_test,\n",
    "                                                              'KNN')\n",
    "\n",
    "    # Decision Tree\n",
    "    dt_model = DecisionTreeRegressor(random_state=42)\n",
    "    dt_param_grid = {'max_depth': [None, 4, 5, 6, 8], 'min_samples_split': [2, 14, 15, 16, 17],\n",
    "                     'min_samples_leaf': [1, 8, 10, 12]}\n",
    "    dt_best_model, dt_mse, dt_y_pred = perform_grid_search(dt_model, dt_param_grid, X_train, y_train, X_test, y_test,\n",
    "                                                           'Decision Tree')\n",
    "\n",
    "    # Support Vector Machine\n",
    "    svm_model = SVR()\n",
    "    svm_param_grid = {'C': [0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 1], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "    svm_best_model, svm_mse, svm_y_pred = perform_grid_search(svm_model, svm_param_grid, X_train, y_train, X_test,\n",
    "                                                              y_test,\n",
    "                                                              'SVM')\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "    xgb_param_grid = {\n",
    "        'n_estimators': [40, 50, 65, 75, 100, 200],\n",
    "        'max_depth': [2, 3, 5, 7, 9],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1],\n",
    "        'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    }\n",
    "    xgb_best_model, xgb_mse, xgb_y_pred = perform_grid_search(xgb_model, xgb_param_grid, X_train, y_train, X_test,\n",
    "                                                              y_test,\n",
    "                                                              'XGBoost')\n",
    "\n",
    "    # Random Forest\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    rf_param_grid = {\n",
    "        #estimators': [100, 200, 300, 500],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        #'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    rf_best_model, rf_mse, rf_y_pred = perform_grid_search(rf_model, rf_param_grid, X_train, y_train, X_test, y_test,\n",
    "                                                           'Random Forest')\n",
    "\n",
    "    # AdaBoost\n",
    "    ada_model = AdaBoostRegressor(random_state=42)\n",
    "    ada_param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200, 500, 1000],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.5, 1]\n",
    "    }\n",
    "    ada_best_model, ada_mse, ada_y_pred = perform_grid_search(ada_model, ada_param_grid, X_train, y_train, X_test,\n",
    "                                                              y_test,\n",
    "                                                              'AdaBoost')\n",
    "\n",
    "    # Bayesian Ridge\n",
    "    bayesian_ridge_model = BayesianRidge()\n",
    "    bay_param_grid = {'max_iter': [50, 100, 200, 300, 400, 500], 'tol': [0.01, 0.002, 1e-3, 1e-4, 1e-5, 1e-6]}\n",
    "    bay_best_model, bay_mse, bay_y_pred = perform_grid_search(bayesian_ridge_model, bay_param_grid, X_train, y_train,\n",
    "\n",
    "                                                              X_test, y_test, 'Bayesian Ridge')\n",
    "\n",
    "    # Linear Regression\n",
    "    linear_regression_model = LinearRegression()\n",
    "    linear_param_grid = {'fit_intercept': [True, False], 'copy_X': [True, False]}\n",
    "    linear_best_model, linear_mse, linear_y_pred = perform_grid_search(linear_regression_model, linear_param_grid,\n",
    "                                                                       X_train,\n",
    "                                                                       y_train,\n",
    "                                                                       X_test, y_test, 'Linear Regression')\n",
    "\n",
    "    # Ridge Regression\n",
    "    ridge_regression_model = Ridge()\n",
    "    ridge_param_grid = {'alpha': [0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 1, 2, 5], 'fit_intercept': [True, False],\n",
    "                        'copy_X': [True, False]}\n",
    "    ridge_best_model, ridge_mse, ridge_y_pred = perform_grid_search(ridge_regression_model, ridge_param_grid, X_train,\n",
    "                                                                    y_train,\n",
    "                                                                    X_test, y_test, 'Ridge Regression')\n",
    "\n",
    "    # Lasso Regression\n",
    "    lasso_regression_model = Lasso()\n",
    "    lasso_param_grid = {'alpha': [0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 1], 'fit_intercept': [True, False],\n",
    "                        'copy_X': [True, False]}\n",
    "    lasso_best_model, lasso_mse, lasso_y_pred = perform_grid_search(lasso_regression_model, lasso_param_grid, X_train,\n",
    "                                                                    y_train,\n",
    "                                                                    X_test, y_test, 'Lasso Regression')\n",
    "\n",
    "    # K-Means\n",
    "    kmeans_model = KMeans()\n",
    "    kmeans_param_grid = {'n_clusters': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
    "    kmeans_best_model, kmeans_mse, kmeans_y_pred = perform_grid_search(kmeans_model, kmeans_param_grid, X_train,\n",
    "                                                                       y_train,\n",
    "                                                                       X_test, y_test, 'K-Means')\n",
    "\n",
    "    # Mean Shift\n",
    "    mean_shift_model = MeanShift()\n",
    "    mean_shift_param_grid = {}\n",
    "    mean_shift_best_model, mean_shift_mse, mean_shift_y_pred = perform_grid_search(mean_shift_model,\n",
    "                                                                                   mean_shift_param_grid, X_train,\n",
    "                                                                          y_train,\n",
    "                                                                            X_test, y_test, 'Mean Shift')\n",
    "\n",
    "\n",
    "    # Neural Network\n",
    "    nn_model = MLPRegressor()\n",
    "    nn_param_grid = {'hidden_layer_sizes': [(300,), (400,), (300, 200), (400, 300), (200, 300)],\n",
    "                     'activation': ['relu', 'tanh', 'logistic'], 'solver': ['adam', 'sgd'],\n",
    "                     'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "    nn_best_model, nn_mse, nn_y_pred = perform_grid_search(nn_model, nn_param_grid, X_train, y_train, X_test, y_test,\n",
    "                                                           'Neural Network')\n",
    "\n",
    "    # Models\n",
    "    models = {\n",
    "        'KNN': knn_best_model,\n",
    "        'Decision Tree': dt_best_model,\n",
    "        'SVM': svm_best_model,\n",
    "        'XGBoost': xgb_best_model,\n",
    "        'Random Forest': rf_best_model,\n",
    "        'AdaBoost': ada_best_model,\n",
    "        'Bayesian Ridge': bay_best_model,\n",
    "        'Linear Regression': linear_best_model,\n",
    "        'Ridge Regression': ridge_best_model,\n",
    "        'Lasso Regression': lasso_best_model,\n",
    "        'K-Means': kmeans_best_model,\n",
    "        'Mean Shift': mean_shift_best_model,\n",
    "        'Neural Network': nn_best_model\n",
    "    }\n",
    "\n",
    "    # Perform model selection\n",
    "    model_errors = model_selection(models, X_train, y_train, X_test, y_test, error_metrics)\n",
    "\n",
    "    # Print model errors\n",
    "    for model_name, errors in model_errors.items():\n",
    "        print(f\"{model_name}:\")\n",
    "        for error_name, error_value in errors.items():\n",
    "            print(f\"  {error_name}: {error_value}\")\n",
    "        print()\n",
    "\n",
    "    # Ensemble all models\n",
    "    knn_y_pred = knn_best_model.predict(X_test)\n",
    "    dt_y_pred = dt_best_model.predict(X_test)\n",
    "    svm_y_pred = svm_best_model.predict(X_test)\n",
    "    xgb_y_pred = xgb_best_model.predict(X_test)\n",
    "    rf_y_pred = rf_best_model.predict(X_test)\n",
    "    ada_y_pred = ada_best_model.predict(X_test)\n",
    "    bay_y_pred = bay_best_model.predict(X_test)\n",
    "    linear_y_pred = linear_best_model.predict(X_test)\n",
    "    ridge_y_pred = ridge_best_model.predict(X_test)\n",
    "    lasso_y_pred = lasso_best_model.predict(X_test)\n",
    "    kmeans_y_pred = kmeans_best_model.predict(X_test)\n",
    "    mean_shift_y_pred = mean_shift_best_model.predict(X_test)\n",
    "    neural_y_pred = nn_best_model.predict(X_test)\n",
    "\n",
    "    ensemble_y_pred = (\n",
    "                              knn_y_pred + dt_y_pred + svm_y_pred + xgb_y_pred + rf_y_pred + ada_y_pred + bay_y_pred + linear_y_pred + ridge_y_pred + lasso_y_pred + kmeans_y_pred + mean_shift_y_pred + neural_y_pred) / 13\n",
    "\n",
    "    with open(dir_path + 'ensemble_error.txt', 'w') as f:\n",
    "        for error in error_metrics:\n",
    "            error_rate = error_metrics[error](y_test, ensemble_y_pred)\n",
    "            print(f\"Ensemble {error}:\", error_rate)\n",
    "            f.write(f\"Ensemble {error}: {error_rate}\\n\")\n",
    "\n",
    "    best_models = sorted(model_errors.items(), key=lambda x: x[1]['MSE'])[:3]\n",
    "    best_models = [model[0] for model in best_models]\n",
    "\n",
    "    ensemble_y_pred_best = np.zeros(len(y_test))\n",
    "    for model_name in best_models:\n",
    "        model = models[model_name]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        ensemble_y_pred_best += y_pred / 3\n",
    "\n",
    "    with open(dir_path + 'ensemble_best_error.txt', 'w') as f:\n",
    "        for error in error_metrics:\n",
    "            error_rate = error_metrics[error](y_test, ensemble_y_pred_best)\n",
    "            print(f\"Ensemble {error}:\", error_rate)\n",
    "            f.write(f\"Ensemble {error}: {error_rate}\\n\")\n",
    "\n",
    "    knn_y_pred = knn_best_model.predict(validation)\n",
    "    dt_y_pred = dt_best_model.predict(validation)\n",
    "    svm_y_pred = svm_best_model.predict(validation)\n",
    "    xgb_y_pred = xgb_best_model.predict(validation)\n",
    "    rf_y_pred = rf_best_model.predict(validation)\n",
    "    ada_y_pred = ada_best_model.predict(validation)\n",
    "    bay_y_pred = bay_best_model.predict(validation)\n",
    "    linear_y_pred = linear_best_model.predict(validation)\n",
    "    ridge_y_pred = ridge_best_model.predict(validation)\n",
    "    lasso_y_pred = lasso_best_model.predict(validation)\n",
    "    kmeans_y_pred = kmeans_best_model.predict(validation)\n",
    "    mean_shift_y_pred = mean_shift_best_model.predict(validation)\n",
    "    neual_y_pred = nn_best_model.predict(validation)\n",
    "    ensemble_y_pred = (\n",
    "                              knn_y_pred + dt_y_pred + svm_y_pred + xgb_y_pred + rf_y_pred + ada_y_pred + bay_y_pred + linear_y_pred + ridge_y_pred + lasso_y_pred + kmeans_y_pred + mean_shift_y_pred + neual_y_pred) / 13\n",
    "\n",
    "    ensemble_y_pred_best = np.zeros(len(validation))\n",
    "    for model_name in best_models:\n",
    "        model = models[model_name]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(validation)\n",
    "        ensemble_y_pred_best += y_pred / 3\n",
    "\n",
    "    predictions = {\n",
    "        'KNN': (knn_mse, knn_y_pred),\n",
    "        'Decision Tree': (dt_mse, dt_y_pred),\n",
    "        'SVM': (svm_mse, svm_y_pred),\n",
    "        'XGBoost': (xgb_mse, xgb_y_pred),\n",
    "        'Random Forest': (rf_mse, rf_y_pred),\n",
    "        'AdaBoost': (ada_mse, ada_y_pred),\n",
    "        'Bayesian Ridge': (bay_mse, bay_y_pred),\n",
    "        'Linear Regression': (linear_mse, linear_y_pred),\n",
    "        'Ridge Regression': (ridge_mse, ridge_y_pred),\n",
    "        'Lasso Regression': (lasso_mse, lasso_y_pred),\n",
    "        'K-Means': (kmeans_mse, kmeans_y_pred),\n",
    "        'Mean Shift': (mean_shift_mse, mean_shift_y_pred),\n",
    "        'Neural Network': (nn_mse, neural_y_pred)\n",
    "    }\n",
    "\n",
    "    for algo_name, (errors, preds) in predictions.items():\n",
    "        preds_df = pd.DataFrame()\n",
    "        preds_df['id'] = validation_ids\n",
    "        preds_df = preds_df.join(pd.DataFrame(preds, columns=['score']))\n",
    "        preds_df.to_csv(dir_path + f'{algo_name}_pred.csv', index=False)\n",
    "        with open(dir_path + f'{algo_name}_error.txt', 'w') as f:\n",
    "            for model_name, errors in model_errors.items():\n",
    "                if model_name == algo_name:\n",
    "                    for error_name, error_value in errors.items():\n",
    "                        f.write(f\"{error_name} for {algo_name}: {error_value}\\n\")\n",
    "\n",
    "    end_preds_df = pd.DataFrame()\n",
    "    end_preds_df['id'] = validation_ids\n",
    "    ensemble_preds_df = end_preds_df.join(pd.DataFrame(ensemble_y_pred, columns=['score']))\n",
    "    ensemble_preds_df.to_csv(dir_path + 'ensemble_pred.csv', index=False)\n",
    "    ensemble_preds_best_df = end_preds_df.join(pd.DataFrame(ensemble_y_pred_best, columns=['score']))\n",
    "    ensemble_preds_best_df.to_csv(dir_path + 'ensemble_best_pred.csv', index=False)\n"
   ],
   "metadata": {
    "id": "XBQxiDE5ltsl",
    "ExecuteTime": {
     "end_time": "2024-01-09T20:27:17.528845Z",
     "start_time": "2024-01-09T20:27:17.511133200Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "id": "t5eaS2eLm2kB",
    "ExecuteTime": {
     "end_time": "2024-01-09T20:27:17.534773700Z",
     "start_time": "2024-01-09T20:27:17.518901400Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def dataset_transform(X, y, validation, test_size=0.2, random_state=42, preprocessing='StandardScaler', preprocessing_params=None, dim_reduction=None,\n",
    "                      dim_reduction_params=None):\n",
    "\n",
    "    data = pd.merge(X, y, on='id')\n",
    "    data = data.drop(['id'], axis=1)\n",
    "\n",
    "    validation_id = validation['id']\n",
    "    validation = validation.drop(['id'], axis=1)\n",
    "\n",
    "    train = data.drop(['score'], axis=1)\n",
    "    y_ = data['score']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, y_,\n",
    "                                                        test_size=test_size,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    preprocessing_steps = []\n",
    "    preprocessing_params = preprocessing_params or {}\n",
    "    scaler = {\n",
    "        'StandardScaler': StandardScaler(**preprocessing_params),\n",
    "        'MinMaxScaler': MinMaxScaler(**preprocessing_params),\n",
    "        'RobustScaler': RobustScaler(**preprocessing_params),\n",
    "        'Normalizer': Normalizer(**preprocessing_params),\n",
    "        'QuantileTransformer': QuantileTransformer(**preprocessing_params),\n",
    "        'PowerTransformer': PowerTransformer(**preprocessing_params),\n",
    "        'PolynomialFeatures': PolynomialFeatures(**preprocessing_params),\n",
    "    }.get(preprocessing)\n",
    "    if scaler:\n",
    "        preprocessing_steps.append(('scaler', scaler))\n",
    "\n",
    "    dim_reduction_params = dim_reduction_params or {}\n",
    "    reducer = {\n",
    "        'PCA': PCA(**dim_reduction_params),\n",
    "        'KernelPCA': KernelPCA(**dim_reduction_params),\n",
    "        'SparsePCA': SparsePCA(**dim_reduction_params),\n",
    "        'TruncatedSVD': TruncatedSVD(**dim_reduction_params),\n",
    "        'FactorAnalysis': FactorAnalysis(**dim_reduction_params),\n",
    "    }.get(dim_reduction)\n",
    "    if reducer:\n",
    "        preprocessing_steps.append(('reducer', reducer))\n",
    "\n",
    "    if preprocessing_steps:\n",
    "        pipeline = Pipeline(steps=preprocessing_steps)\n",
    "        X_train = pipeline.fit_transform(X_train)\n",
    "        X_test = pipeline.transform(X_test)\n",
    "        validation = pipeline.transform(validation)\n",
    "    else:\n",
    "        raise ValueError(\"No valid preprocessing or dimensionality reduction method provided\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "    dir_path = f\"results/{preprocessing}_{dim_reduction}/\"\n",
    "    return X_train, X_test, y_train, y_test, validation, validation_id, dir_path"
   ],
   "metadata": {
    "id": "8hu_f9GTmuhR",
    "ExecuteTime": {
     "end_time": "2024-01-09T20:27:17.543073200Z",
     "start_time": "2024-01-09T20:27:17.527247Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    X_train = pd.read_csv('pc_X_train.csv')\n",
    "    y_train = pd.read_csv('pc_y_train.csv')\n",
    "    validation = pd.read_csv('pc_X_test.csv')\n",
    "\n",
    "    X_train, X_test, y_train, y_test, validation, validation_id, dir_path = dataset_transform(\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        validation=validation,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        preprocessing='PowerTransformer', # StandardScaler, MinMaxScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer, PolynomialFeatures\n",
    "        preprocessing_params={},\n",
    "        dim_reduction='SparsePCA',  # PCA, KernelPCA, SparsePCA, TruncatedSVD, FactorAnalysis\n",
    "        dim_reduction_params={},\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "\n",
    "    run_models(X_train, X_test, y_train, y_test, validation, validation_id, dir_path)"
   ],
   "metadata": {
    "id": "kzarWjnimeaV",
    "ExecuteTime": {
     "end_time": "2024-01-09T20:27:17.550519900Z",
     "start_time": "2024-01-09T20:27:17.533761300Z"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "159oBk5YnA2z",
    "outputId": "b097968e-a95b-47c5-bbb1-5b5fe79836d9",
    "ExecuteTime": {
     "end_time": "2024-01-09T21:45:11.410423900Z",
     "start_time": "2024-01-09T20:27:17.549529500Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Csana\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "C:\\Users\\Csana\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1580, 468)\n",
      "X_test shape: (396, 468)\n",
      "y_train shape: (1580,)\n",
      "y_test shape: (396,)\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "Best Parameters for KNN: {'algorithm': 'auto', 'leaf_size': 5, 'n_neighbors': 19, 'p': 1, 'weights': 'distance'}\n",
      "Mean Squared Error for KNN (Best Model): 0.4306189724143329\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Parameters for Decision Tree: {'max_depth': 4, 'min_samples_leaf': 12, 'min_samples_split': 2}\n",
      "Mean Squared Error for Decision Tree (Best Model): 0.5142714439970607\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "Best Parameters for SVM: {'C': 0.7, 'kernel': 'rbf'}\n",
      "Mean Squared Error for SVM (Best Model): 0.4066157560135386\n",
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n",
      "Best Parameters for XGBoost: {'colsample_bytree': 0.9, 'max_depth': 2, 'n_estimators': 40, 'subsample': 1}\n",
      "Mean Squared Error for XGBoost (Best Model): 0.3992076013410574\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters for Random Forest: {'max_depth': None, 'min_samples_leaf': 4}\n",
      "Mean Squared Error for Random Forest (Best Model): 0.393091856197531\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters for AdaBoost: {'learning_rate': 1, 'n_estimators': 150}\n",
      "Mean Squared Error for AdaBoost (Best Model): 0.4153221328540457\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters for Bayesian Ridge: {'max_iter': 50, 'tol': 0.01}\n",
      "Mean Squared Error for Bayesian Ridge (Best Model): 0.42115723892073453\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Parameters for Linear Regression: {'copy_X': True, 'fit_intercept': False}\n",
      "Mean Squared Error for Linear Regression (Best Model): 15.06331535625375\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters for Ridge Regression: {'alpha': 5, 'copy_X': True, 'fit_intercept': True}\n",
      "Mean Squared Error for Ridge Regression (Best Model): 0.4093421684282529\n",
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "Best Parameters for Lasso Regression: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True}\n",
      "Mean Squared Error for Lasso Regression (Best Model): 0.46250112525142495\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Csana\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for K-Means: {'n_clusters': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Csana\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for K-Means (Best Model): 7.127525252525253\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Parameters for Mean Shift: {}\n",
      "Mean Squared Error for Mean Shift (Best Model): 14.738636363636363\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Csana\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Neural Network: {'activation': 'logistic', 'hidden_layer_sizes': (300,), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Csana\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Neural Network (Best Model): 0.4266798732192248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Csana\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\Csana\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "  MSE: 0.4306189724143329\n",
      "  rMSE: 0.6562156447497521\n",
      "  relative: 16.64961631487319\n",
      "  relativeSE: 8.242944048742777\n",
      "  absoluteSE: 0.5015972494414369\n",
      "  statistical correlation: 0.5564987437483924\n",
      "\n",
      "Decision Tree:\n",
      "  MSE: 0.5142714439970607\n",
      "  rMSE: 0.7171272160482133\n",
      "  relative: 18.368724430519404\n",
      "  relativeSE: 10.011709343773733\n",
      "  absoluteSE: 0.5496771143516019\n",
      "  statistical correlation: 0.47034374684362334\n",
      "\n",
      "SVM:\n",
      "  MSE: 0.4066157560135386\n",
      "  rMSE: 0.6376642972705455\n",
      "  relative: 16.365033109957213\n",
      "  relativeSE: 8.376035371979142\n",
      "  absoluteSE: 0.4831021986902062\n",
      "  statistical correlation: 0.5812200340532436\n",
      "\n",
      "XGBoost:\n",
      "  MSE: 0.3992076013410574\n",
      "  rMSE: 0.6318287753347875\n",
      "  relative: 15.866879224073507\n",
      "  relativeSE: 7.045204457879708\n",
      "  absoluteSE: 0.48508832460702067\n",
      "  statistical correlation: 0.5888498091310364\n",
      "\n",
      "Random Forest:\n",
      "  MSE: 0.393091856197531\n",
      "  rMSE: 0.6269703790431658\n",
      "  relative: 15.678937271260487\n",
      "  relativeSE: 7.009036889425538\n",
      "  absoluteSE: 0.476193562563964\n",
      "  statistical correlation: 0.595148511296576\n",
      "\n",
      "AdaBoost:\n",
      "  MSE: 0.4153221328540457\n",
      "  rMSE: 0.6444549114205319\n",
      "  relative: 15.994126569315073\n",
      "  relativeSE: 6.523763364068358\n",
      "  absoluteSE: 0.5032225651805816\n",
      "  statistical correlation: 0.572253199534746\n",
      "\n",
      "Bayesian Ridge:\n",
      "  MSE: 0.42115723892073453\n",
      "  rMSE: 0.648966284887539\n",
      "  relative: 16.3960203657498\n",
      "  relativeSE: 8.261632132144534\n",
      "  absoluteSE: 0.49234269700554073\n",
      "  statistical correlation: 0.5662435319708007\n",
      "\n",
      "Linear Regression:\n",
      "  MSE: 15.06331535625375\n",
      "  rMSE: 3.88114871607025\n",
      "  relative: 96.82565290669649\n",
      "  relativeSE: 123.52749637992116\n",
      "  absoluteSE: 3.4305350563742896\n",
      "  statistical correlation: -14.513945533697324\n",
      "\n",
      "Ridge Regression:\n",
      "  MSE: 0.4093421684282529\n",
      "  rMSE: 0.6397985373758313\n",
      "  relative: 16.053647166926098\n",
      "  relativeSE: 6.593363657342007\n",
      "  absoluteSE: 0.49756833041580983\n",
      "  statistical correlation: 0.5784120590023387\n",
      "\n",
      "Lasso Regression:\n",
      "  MSE: 0.46250112525142495\n",
      "  rMSE: 0.6800743527375701\n",
      "  relative: 17.446202887565935\n",
      "  relativeSE: 9.964735202756277\n",
      "  absoluteSE: 0.5169419859539266\n",
      "  statistical correlation: 0.523662812818598\n",
      "\n",
      "K-Means:\n",
      "  MSE: 5.61489898989899\n",
      "  rMSE: 2.3695778083656567\n",
      "  relative: 54.649434460040524\n",
      "  relativeSE: 44.949375831205494\n",
      "  absoluteSE: 1.9848484848484849\n",
      "  statistical correlation: -4.782872830206029\n",
      "\n",
      "Mean Shift:\n",
      "  MSE: 14.738636363636363\n",
      "  rMSE: 3.8390931694394137\n",
      "  relative: 99.74585319282289\n",
      "  relativeSE: 99.5971822269239\n",
      "  absoluteSE: 3.712121212121212\n",
      "  statistical correlation: -14.179553529794235\n",
      "\n",
      "Neural Network:\n",
      "  MSE: 0.42600768883953954\n",
      "  rMSE: 0.6526926450018719\n",
      "  relative: 16.55198622832511\n",
      "  relativeSE: 8.39610383510192\n",
      "  absoluteSE: 0.49540394024323314\n",
      "  statistical correlation: 0.561247977268892\n",
      "Ensemble MSE: 0.7369150911756718\n",
      "Ensemble rMSE: 0.8584375872337323\n",
      "Ensemble relative: 19.376862993817117\n",
      "Ensemble relativeSE: 6.32390575244625\n",
      "Ensemble absoluteSE: 0.6985075163062157\n",
      "Ensemble statistical correlation: 0.2410395509171478\n",
      "Ensemble MSE: 0.3835255585325581\n",
      "Ensemble rMSE: 0.6192944037633136\n",
      "Ensemble relative: 15.6592698932358\n",
      "Ensemble relativeSE: 7.2801671826532965\n",
      "Ensemble absoluteSE: 0.4705638437250476\n",
      "Ensemble statistical correlation: 0.605000991804588\n"
     ]
    }
   ]
  }
 ]
}
